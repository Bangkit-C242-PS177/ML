{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Model\n",
    "This model is the model that used to detect user's face before classifying its type and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries, Mobilenet, and Env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Env File\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "datasets_path = os.getenv('DATASET_PATH_HUMAN_FACES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MobileNetV2 Model With ImagNet Weight Without The Top Layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membekukan semua lapisan dari model MobileNetV2\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: Membuka beberapa lapisan terakhir dari MobileNetV2\n",
    "for layer in base_model.layers[-5:]:  # Mengatur lebih banyak lapisan terakhir dapat dilatih\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Model (If Exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model from .h5 file\n",
    "model = load_model('models/face_detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "class FaceDetectionDataset(tfds.core.GeneratorBasedBuilder):\n",
    "    \"\"\"DatasetBuilder for skin type detection.\"\"\"\n",
    "    VERSION = tfds.core.Version('1.0.0')\n",
    "    MANUAL_DOWNLOAD_INSTRUCTIONS = \"Please ensure the face detection dataset is downloaded and located at the right path (look at env file)\"\n",
    "\n",
    "    def _info(self):\n",
    "        return tfds.core.DatasetInfo(\n",
    "            builder=self,\n",
    "            description=(\"Dataset for face detectionn with 2 labels: human, not_human\"),\n",
    "            features=tfds.features.FeaturesDict({\n",
    "                'image': tfds.features.Image(shape=(224, 224, 3)),\n",
    "                'label': tfds.features.Tensor(shape=(2,), dtype=tf.float32),\n",
    "            }),\n",
    "            supervised_keys=('image', 'label'),\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        path = dl_manager.manual_dir\n",
    "        # Read all images and labels\n",
    "        all_data = []\n",
    "        for category in ['human', 'not_human']:\n",
    "            category_path = os.path.join(path, category)\n",
    "            for filename in os.listdir(category_path):\n",
    "                all_data.append((filename, category))\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(all_data, columns=['filename', 'label'])\n",
    "        \n",
    "        # Split data into train, val, and test\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # 0.25 of train for validation\n",
    "        \n",
    "        return {\n",
    "            'train': self._generate_examples(train_df, path),\n",
    "            'val': self._generate_examples(val_df, path),\n",
    "            'test': self._generate_examples(test_df, path),\n",
    "        }\n",
    "\n",
    "    def _generate_examples(self, dataframe, base_path):\n",
    "        label_map = {\n",
    "            'human': [1, 0],\n",
    "            'not_human': [0, 1],\n",
    "        }\n",
    "        # Load images and their labels\n",
    "        for _, row in dataframe.iterrows():\n",
    "            image_path = os.path.join(base_path, row['label'], row['filename'])\n",
    "            image = tf.io.read_file(image_path)  # Read image file\n",
    "            image = tf.io.decode_image(image, channels=3)  # Decode image to tensor\n",
    "            image = tf.image.resize(image, (224, 224))  # Resize image\n",
    "            image = tf.cast(image, tf.uint8)  # Convert to uint8\n",
    "            label = tf.cast(label_map[row['label']], tf.float32)  # Cast to float32\n",
    "            yield row['filename'], {  # Use filename as the unique key\n",
    "                'image': image.numpy(),\n",
    "                'label': label.numpy(),\n",
    "            }\n",
    "\n",
    "# Use the updated dataset class\n",
    "builder = FaceDetectionDataset(data_dir=datasets_path)\n",
    "builder.download_and_prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat dataset dalam bentuk builder untuk melakukan cek\n",
    "ds_train = builder.as_dataset(split='train')\n",
    "ds_val = builder.as_dataset(split='val')\n",
    "ds_test = builder.as_dataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dan tampilkan label dengan nilai [1, 0]\n",
    "for i, example in enumerate(ds_train):\n",
    "    label = example['label'].numpy()  # Ambil label sebagai numpy array\n",
    "    if (label == [1, 0]).all():    \n",
    "        print(f\"Label {i + 1}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fungsi untuk menampilkan gambar\n",
    "def show_image(image):\n",
    "    # Konversi gambar tensor ke numpy array dan tampilkan dengan matplotlib\n",
    "    image = image.numpy()  # Ubah tensor menjadi numpy array\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Nonaktifkan axis\n",
    "    plt.show()\n",
    "\n",
    "# Fungsi untuk menampilkan beberapa gambar\n",
    "def show_images_from_dataset(dataset, num_images=5):\n",
    "    for i, data in enumerate(dataset.take(num_images)):  # Ambil beberapa gambar pertama dari dataset\n",
    "        image = data['image']\n",
    "        # Tampilkan gambar\n",
    "        show_image(image)\n",
    "\n",
    "# Menampilkan gambar pertama dari ds_train\n",
    "show_images_from_dataset(ds_train, num_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset And Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat dataset yang sudah diproses\n",
    "ds_train = tfds.load('skin_type_dataset', split='train', data_dir=datasets_path)\n",
    "ds_val = tfds.load('skin_type_dataset', split='val', data_dir=datasets_path)\n",
    "ds_test = tfds.load('skin_type_dataset', split='test', data_dir=datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Function to ensure data is paired as (image, label)\n",
    "def preprocess(data):\n",
    "    image = data['image']\n",
    "    label = data['label']\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing and augmentation\n",
    "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Batch and prefetch the datasets\n",
    "ds_train = ds_train.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jumlah data dalam ds_train\n",
    "num_samples = sum(1 for _ in ds_train)\n",
    "# num_samples = sum(1 for _ in ds_train.unbatch())\n",
    "\n",
    "print(f\"Jumlah gambar dan label dalam ds_train: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization, GlobalAveragePooling2D, Dense, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Menambahkan lapisan kustom di atas MobileNetV2\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) \n",
    "x = Dense(256, kernel_regularizer=l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)  # ReLU activation setelah batch normalization\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))(x)  # Sigmoid untuk binary classification\n",
    "\n",
    "# Membuat model akhir\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Menyesuaikan optimizer dan learning rate \n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9)\n",
    "\n",
    "# Compiling the model \n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Model Architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds_train.take(1):\n",
    "    print(image.shape, label.shape)  # Pastikan gambar memiliki shape (32, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Callback untuk menghentikan pelatihan jika validasi loss tidak membaik\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',                  \n",
    "    patience=5,                         \n",
    "    restore_best_weights=True,           \n",
    "    verbose=1                            \n",
    ")\n",
    "\n",
    "# Callback untuk mengurangi learning rate jika validasi loss stagnan\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',                \n",
    "    factor=0.5,                         \n",
    "    patience=3,                         \n",
    "    verbose=1                           \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = {0: 0.6 , 1: 1.2 , 2: 0.6}  # Sesuaikan bobot berdasarkan kinerja kelas\n",
    "\n",
    "# Melatih model dan mencatat hasil pelatihan dalam objek `history`\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=30,\n",
    "    # class_weight=class_weight,\n",
    "    callbacks=[early_stopping, lr_scheduler] \n",
    ")\n",
    "\n",
    "# Menampilkan metrik dengan matplotlib\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluasi model pada data testing\n",
    "loss, accuracy = model.evaluate(ds_test)\n",
    "print(f'Testing Loss: {loss}, Testing Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil nilai akurasi pada epoch terbaik\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "\n",
    "train_accuracy = history.history['accuracy'][best_epoch] \n",
    "val_accuracy = history.history['val_accuracy'][best_epoch]\n",
    "\n",
    "# Akurasi data testing (sudah didapat dari evaluasi model sebelumnya)\n",
    "test_accuracy = accuracy\n",
    "\n",
    "# Buat bar chart\n",
    "labels = ['Training Accuracy', 'Validation Accuracy', 'Testing Accuracy']\n",
    "accuracies = [train_accuracy, val_accuracy, test_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, accuracies, color=['blue', 'orange', 'green'])\n",
    "plt.ylim(0, 1)  # Atur batas y dari 0 sampai 1\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat prediksi pada data testing\n",
    "y_pred = model.predict(ds_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Mendapatkan label aktual\n",
    "y_true = np.concatenate([y for x, y in ds_test], axis=0)\n",
    "y_true_classes = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Menghitung confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Menampilkan confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['human', 'not human'], yticklabels=['human', 'not human'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Menampilkan laporan klasifikasi\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=['Oily', 'Normal', 'Dry']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model in .h5 format\n",
    "model.save('models/face_detection.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
